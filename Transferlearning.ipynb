{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Dependencies\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pprint as pp\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import keras\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg19 import (\n",
    "    VGG19, preprocess_input, decode_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the VGG19 model\n",
    "# https://keras.io/applications/#VGG19\n",
    "model = VGG19(\n",
    "    include_top=False, \n",
    "    weights='imagenet')\n",
    "model_original = VGG19(\n",
    "    include_top=True, \n",
    "    weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<keras.engine.input_layer.InputLayer object at 0x00000153AB564860>,\n",
      " <keras.layers.convolutional.Conv2D object at 0x00000153A19C0160>,\n",
      " <keras.layers.convolutional.Conv2D object at 0x00000153B0BEEBA8>,\n",
      " <keras.layers.pooling.MaxPooling2D object at 0x00000153B0B9D7F0>,\n",
      " <keras.layers.convolutional.Conv2D object at 0x00000153B0BFCD68>,\n",
      " <keras.layers.convolutional.Conv2D object at 0x00000153B0C0CAC8>,\n",
      " <keras.layers.pooling.MaxPooling2D object at 0x00000153B0C19C18>,\n",
      " <keras.layers.convolutional.Conv2D object at 0x00000153B0B80F28>,\n",
      " <keras.layers.convolutional.Conv2D object at 0x00000153ABDA5D30>,\n",
      " <keras.layers.convolutional.Conv2D object at 0x00000153ABDB9F28>,\n",
      " <keras.layers.convolutional.Conv2D object at 0x00000153B0BB5C18>,\n",
      " <keras.layers.pooling.MaxPooling2D object at 0x00000153B0B9A1D0>,\n",
      " <keras.layers.convolutional.Conv2D object at 0x00000153ABDD7A58>,\n",
      " <keras.layers.convolutional.Conv2D object at 0x00000153ABDE5B38>,\n",
      " <keras.layers.convolutional.Conv2D object at 0x00000153ABDF86D8>,\n",
      " <keras.layers.convolutional.Conv2D object at 0x00000153ABE0F828>,\n",
      " <keras.layers.pooling.MaxPooling2D object at 0x00000153ABE1FB38>,\n",
      " <keras.layers.convolutional.Conv2D object at 0x00000153ABE52F60>,\n",
      " <keras.layers.convolutional.Conv2D object at 0x00000153ABE3BF28>,\n",
      " <keras.layers.convolutional.Conv2D object at 0x00000153ABE66160>,\n",
      " <keras.layers.convolutional.Conv2D object at 0x00000153ABE78EF0>,\n",
      " <keras.layers.pooling.MaxPooling2D object at 0x00000153ABE9AFD0>,\n",
      " <keras.layers.core.Flatten object at 0x00000153ABEC4710>,\n",
      " <keras.layers.core.Dense object at 0x00000153ABEE6AC8>,\n",
      " <keras.layers.core.Dense object at 0x00000153ABEF7FD0>,\n",
      " <keras.layers.core.Dense object at 0x00000153ABF0B208>]\n",
      "<tf.Tensor 'predictions/Softmax:0' shape=(?, 1000) dtype=float32>\n"
     ]
    }
   ],
   "source": [
    "pp.pprint(model_original.layers)\n",
    "pp.pprint(model_original.output)\n",
    "\n",
    "# model_original.layers[25].\n",
    "#Question: how do i check properties (like dimensions) of a particular layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<keras.engine.input_layer.InputLayer object at 0x00000153AB5647F0>,\n",
      " <keras.layers.convolutional.Conv2D object at 0x00000153AB564E10>,\n",
      " <keras.layers.convolutional.Conv2D object at 0x00000153AB582FD0>,\n",
      " <keras.layers.pooling.MaxPooling2D object at 0x00000153AB564B38>,\n",
      " <keras.layers.convolutional.Conv2D object at 0x00000153AB564C50>,\n",
      " <keras.layers.convolutional.Conv2D object at 0x00000153AB5F7AC8>,\n",
      " <keras.layers.pooling.MaxPooling2D object at 0x00000153AB60B748>,\n",
      " <keras.layers.convolutional.Conv2D object at 0x00000153AB61D5F8>,\n",
      " <keras.layers.convolutional.Conv2D object at 0x00000153AB61DFD0>,\n",
      " <keras.layers.convolutional.Conv2D object at 0x00000153AB648E48>,\n",
      " <keras.layers.convolutional.Conv2D object at 0x00000153AB658780>,\n",
      " <keras.layers.pooling.MaxPooling2D object at 0x00000153AB67C908>,\n",
      " <keras.layers.convolutional.Conv2D object at 0x00000153AB68F198>,\n",
      " <keras.layers.convolutional.Conv2D object at 0x00000153ABC455C0>,\n",
      " <keras.layers.convolutional.Conv2D object at 0x00000153ABC358D0>,\n",
      " <keras.layers.convolutional.Conv2D object at 0x00000153ABC69D68>,\n",
      " <keras.layers.pooling.MaxPooling2D object at 0x00000153ABC786A0>,\n",
      " <keras.layers.convolutional.Conv2D object at 0x00000153ABC94E48>,\n",
      " <keras.layers.convolutional.Conv2D object at 0x00000153ABCB46A0>,\n",
      " <keras.layers.convolutional.Conv2D object at 0x00000153ABCC8B00>,\n",
      " <keras.layers.convolutional.Conv2D object at 0x00000153ABCD9160>,\n",
      " <keras.layers.pooling.MaxPooling2D object at 0x00000153ABD15FD0>]\n",
      "<tf.Tensor 'block5_pool/MaxPool:0' shape=(?, ?, ?, 512) dtype=float32>\n"
     ]
    }
   ],
   "source": [
    "pp.pprint(model.layers)\n",
    "pp.pprint(model.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a global spatial average pooling layer\n",
    "x = model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "# let's add a fully-connected layer\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "# and a logistic layer -- let's say we have 200 classes\n",
    "predictions = Dense(2, activation='softmax')(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this is the model we will train\n",
    "model = Model(inputs=model.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n",
      "(299, 299, 3)\n"
     ]
    }
   ],
   "source": [
    "# load image data\n",
    "import glob\n",
    "images_path= glob.glob('./imgs_with_filter/imgs_with_filter/*')\n",
    "images_list=[]\n",
    "labels=[]\n",
    "image_size = (299, 299)\n",
    "for img_path in images_path:\n",
    "    image_stored=image.load_img(img_path,target_size=image_size)\n",
    "    \n",
    "    # Preprocess image for model prediction\n",
    "# This step handles scaling and normalization for Xception\n",
    "    x = image.img_to_array(image_stored)\n",
    "#     x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    print(x.shape)\n",
    "    images_list.append(x)\n",
    "    labels.append([False, True])\n",
    "# X=images_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.array(images_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       ..., \n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True]], dtype=bool)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.array(labels)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#splitting data into test and train\n",
    "from sklearn.model_selection import train_test_split\n",
    "y=np.ones(len(images_list))\n",
    "print(y.shape)\n",
    "X_train,X_test,y_train,y_test=train_test_split(images_list,y,test_size=0.33,shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      " 150/1107 [===>..........................] - ETA: 35:39 - loss: 0.9975"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-d3a6a51cbdd5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m# train the model on the new data for a few epochs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# model.fit_generator(\"\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1040\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1042\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1043\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1044\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2659\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2660\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2661\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2662\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2663\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2629\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2630\u001b[0m                                 session)\n\u001b[1;32m-> 2631\u001b[1;33m         \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2632\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2633\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1449\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_with_new_api\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1450\u001b[0m           return tf_session.TF_SessionRunCallable(\n\u001b[1;32m-> 1451\u001b[1;33m               self._session._session, self._handle, args, status, None)\n\u001b[0m\u001b[0;32m   1452\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1453\u001b[0m           return tf_session.TF_DeprecatedSessionRunCallable(\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# first: train only the top layers (which were randomly initialized)\n",
    "# i.e. freeze all convolutional InceptionV3 layers\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# compile the model (should be done *after* setting layers to non-trainable)\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
    "\n",
    "# train the model on the new data for a few epochs\n",
    "# model.fit_generator(\"\")\n",
    "model.fit(X,y,batch_size=50,epochs=1,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "`steps_per_epoch=None` is only valid for a generator based on the `keras.utils.Sequence` class. Please specify `steps_per_epoch` or use the `keras.utils.Sequence` class.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-41640da40ec5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m# train the model on the new data for a few epochs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m...\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m# at this point, the top layers are well trained and we can start fine-tuning\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[0;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1424\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1425\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1426\u001b[1;33m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1427\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1428\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m     50\u001b[0m             \u001b[0msteps_per_epoch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m             raise ValueError('`steps_per_epoch=None` is only valid for a'\n\u001b[0m\u001b[0;32m     53\u001b[0m                              \u001b[1;34m' generator based on the '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m                              \u001b[1;34m'`keras.utils.Sequence`'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: `steps_per_epoch=None` is only valid for a generator based on the `keras.utils.Sequence` class. Please specify `steps_per_epoch` or use the `keras.utils.Sequence` class."
     ]
    }
   ],
   "source": [
    "# at this point, the top layers are well trained and we can start fine-tuning\n",
    "# convolutional layers from inception V3. We will freeze the bottom N layers\n",
    "# and train the remaining top layers.\n",
    "\n",
    "# let's visualize layer names and layer indices to see how many layers\n",
    "# we should freeze:\n",
    "for i, layer in enumerate(base_model.layers):\n",
    "   print(i, layer.name)\n",
    "\n",
    "# we chose to train the top 2 inception blocks, i.e. we will freeze\n",
    "# the first 249 layers and unfreeze the rest:\n",
    "for layer in model.layers[:249]:\n",
    "   layer.trainable = False\n",
    "for layer in model.layers[249:]:\n",
    "   layer.trainable = True\n",
    "\n",
    "# we need to recompile the model for these modifications to take effect\n",
    "# we use SGD with a low learning rate\n",
    "from keras.optimizers import SGD\n",
    "model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='categorical_crossentropy')\n",
    "\n",
    "# we train our model again (this time fine-tuning the top 2 inception blocks\n",
    "# alongside the top Dense layers\n",
    "model.fit_generator(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
